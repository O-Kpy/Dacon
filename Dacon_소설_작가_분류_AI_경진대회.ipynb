{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dacon-소설 작가 분류 AI 경진대회.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zwEQCNKvnm12kYlGXJ_AhkuGzF65toq-",
      "authorship_tag": "ABX9TyPY3B+xtUy6wTjUHeLxpHr6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4816c7c96a774acc88d513dde7151fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af53ae0613374aaf991e00f6110cfd0a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f39aee9f02274c8ca8b75a624eedd965",
              "IPY_MODEL_26418c10ee8547d0bcc969d4d59a5825"
            ]
          }
        },
        "af53ae0613374aaf991e00f6110cfd0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f39aee9f02274c8ca8b75a624eedd965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_195c5de9ff98447f97201ec2810a9ade",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6769b5bdd9f74d0ca2fcddb5510ac67b"
          }
        },
        "26418c10ee8547d0bcc969d4d59a5825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4086c431f6d94bc9a4e1111028c4377f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:02&lt;00:00, 90.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae72ef5e7172408aa08da30d243af840"
          }
        },
        "195c5de9ff98447f97201ec2810a9ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6769b5bdd9f74d0ca2fcddb5510ac67b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4086c431f6d94bc9a4e1111028c4377f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae72ef5e7172408aa08da30d243af840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdeabd4bea0c4dd58fad43668814c531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9ff31d92f9143718a6e1aefe151606c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7efd8f08b18a4018bde1dc46f2ca7ba3",
              "IPY_MODEL_69faa684481a43528ac954eed70f91c9"
            ]
          }
        },
        "f9ff31d92f9143718a6e1aefe151606c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7efd8f08b18a4018bde1dc46f2ca7ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0bda79c387594b96a01b9e8eff2f0b4a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b7085e0bf7246c297aae5c2d4b4a8c3"
          }
        },
        "69faa684481a43528ac954eed70f91c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70e22c8d72e7400897f69fa2bcfa255e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:01&lt;00:00, 26.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9d50462716c476288d173040df25d57"
          }
        },
        "0bda79c387594b96a01b9e8eff2f0b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b7085e0bf7246c297aae5c2d4b4a8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70e22c8d72e7400897f69fa2bcfa255e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9d50462716c476288d173040df25d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53ef4727522e4e80b9b7d8f2f4091410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1267b812159b44689e104e0f6a0626ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f05a2cd64594a719f69160f13d1839b",
              "IPY_MODEL_d2e83869077547e3a4ad6f3925f4852b"
            ]
          }
        },
        "1267b812159b44689e104e0f6a0626ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f05a2cd64594a719f69160f13d1839b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4547c9533ad14c979ec79f59a28cc932",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2dbd3bad05724663b28b5716906c72f8"
          }
        },
        "d2e83869077547e3a4ad6f3925f4852b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c78bbe08d5046adaf9b16ce2f97d992",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 2.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a838f8c03404b8ca71517d76af5a16c"
          }
        },
        "4547c9533ad14c979ec79f59a28cc932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2dbd3bad05724663b28b5716906c72f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c78bbe08d5046adaf9b16ce2f97d992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a838f8c03404b8ca71517d76af5a16c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/O-Kpy/Dacon/blob/main/Dacon_%E1%84%89%E1%85%A9%E1%84%89%E1%85%A5%E1%86%AF_%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%80%E1%85%A1_%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2_AI_%E1%84%80%E1%85%A7%E1%86%BC%E1%84%8C%E1%85%B5%E1%86%AB%E1%84%83%E1%85%A2%E1%84%92%E1%85%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLHXN7L8Mayj",
        "outputId": "b55cfb97-b2ca-4585-b6eb-17365ad2a3ce"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooSpTXFlMvO0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, SequentialSampler, random_split, RandomSampler\n",
        "\n",
        "\n",
        "import transformers\n",
        "from transformers import BertConfig, BertModel, BertTokenizer, AdamW, DistilBertModel, DistilBertTokenizer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQN6JcuMMiPj",
        "outputId": "d1ad8ada-d39e-4cc7-e3c1-86e965470e3d"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/dataset/Dacon/연습/소설 작가 분류 AI 경진대회_data/소설 작가 분류 AI 경진대회_data-train.csv', encoding='utf-8')\n",
        "test = pd.read_csv('/content/drive/MyDrive/dataset/Dacon/연습/소설 작가 분류 AI 경진대회_data/소설 작가 분류 AI 경진대회_data-test_x.csv', encoding='utf-8')\n",
        "submit = pd.read_csv('/content/drive/MyDrive/dataset/Dacon/연습/소설 작가 분류 AI 경진대회_data/소설 작가 분류 AI 경진대회_data-sample_submission.csv', encoding='utf-8')\n",
        "train.shape, test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((54879, 3), (19617, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHxgAm94SoUI",
        "outputId": "3e02d86b-b760-4176-9a2d-8877e27c2949"
      },
      "source": [
        "# 토큰화\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "sequence_len = 160\n",
        "x_train_tokens = []\n",
        "attention_mask = []\n",
        "\n",
        "for text in train['text']:\n",
        "  encoded_dict = tokenizer.encode_plus(text,\n",
        "                                       add_special_tokens=True,\n",
        "                                       max_length=sequence_len,\n",
        "                                       padding='max_length',\n",
        "                                       return_tensors='pt',\n",
        "                                       truncation=True)\n",
        "\n",
        "  x_train_tokens.append(encoded_dict['input_ids'])\n",
        "  attention_mask.append(encoded_dict['attention_mask'])\n",
        "\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "x_train_tokens = torch.cat(x_train_tokens, dim=0)\n",
        "attention_mask = torch.cat(attention_mask, dim=0)\n",
        "y_train = torch.tensor(train['author'])\n",
        "\n",
        "x_train_tokens.size(), attention_mask.size(), y_train.size()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([54879, 160]), torch.Size([54879, 160]), torch.Size([54879]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XV07ygrYlFE"
      },
      "source": [
        "# Data Load\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 16\n",
        "\n",
        "dataset = TensorDataset(x_train_tokens.to(device),\n",
        "                        attention_mask.to(device),\n",
        "                        y_train.double().to(device))\n",
        "\n",
        "train_size = int(len(dataset)*0.8)\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, valid_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_set,\n",
        "                          sampler=RandomSampler(train_set),\n",
        "                          batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_set,\n",
        "                          sampler=RandomSampler(valid_set),\n",
        "                          batch_size=batch_size)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1y6zW5gbWxu",
        "outputId": "d010faac-bab3-4a0f-b66c-67c16e0b754d"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert.to(device)\n",
        "\n",
        "example_batch = next(iter(train_loader))\n",
        "\n",
        "print('what is drawn from our dataloader?', type(example_batch))\n",
        "print('\\nfirst entry:', example_batch[0].size(), type(example_batch[0]), example_batch[0].dtype)\n",
        "print(\"\\nsecond entry: \", example_batch[1].size(), type(example_batch[1]), example_batch[1].dtype)\n",
        "\n",
        "batch_features = example_batch[0].to(device)\n",
        "bert_output = bert(input_ids=batch_features)\n",
        "print('bert output:', type(bert_output), len(bert_output))\n",
        "print('first entry:', type(bert_output[0]), bert_output[0].size())\n",
        "print('second entry:', type(bert_output[1]), bert_output[1].size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "what is drawn from our dataloader? <class 'list'>\n",
            "\n",
            "first entry: torch.Size([16, 160]) <class 'torch.Tensor'> torch.int64\n",
            "\n",
            "second entry:  torch.Size([16, 160]) <class 'torch.Tensor'> torch.int64\n",
            "bert output: <class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'> 2\n",
            "first entry: <class 'torch.Tensor'> torch.Size([16, 160, 768])\n",
            "second entry: <class 'torch.Tensor'> torch.Size([16, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238,
          "referenced_widgets": [
            "4816c7c96a774acc88d513dde7151fc4",
            "af53ae0613374aaf991e00f6110cfd0a",
            "f39aee9f02274c8ca8b75a624eedd965",
            "26418c10ee8547d0bcc969d4d59a5825",
            "195c5de9ff98447f97201ec2810a9ade",
            "6769b5bdd9f74d0ca2fcddb5510ac67b",
            "4086c431f6d94bc9a4e1111028c4377f",
            "ae72ef5e7172408aa08da30d243af840",
            "bdeabd4bea0c4dd58fad43668814c531",
            "f9ff31d92f9143718a6e1aefe151606c",
            "7efd8f08b18a4018bde1dc46f2ca7ba3",
            "69faa684481a43528ac954eed70f91c9",
            "0bda79c387594b96a01b9e8eff2f0b4a",
            "9b7085e0bf7246c297aae5c2d4b4a8c3",
            "70e22c8d72e7400897f69fa2bcfa255e",
            "f9d50462716c476288d173040df25d57",
            "53ef4727522e4e80b9b7d8f2f4091410",
            "1267b812159b44689e104e0f6a0626ae",
            "8f05a2cd64594a719f69160f13d1839b",
            "d2e83869077547e3a4ad6f3925f4852b",
            "4547c9533ad14c979ec79f59a28cc932",
            "2dbd3bad05724663b28b5716906c72f8",
            "9c78bbe08d5046adaf9b16ce2f97d992",
            "8a838f8c03404b8ca71517d76af5a16c"
          ]
        },
        "id": "PeGMu1j53HDd",
        "outputId": "d9c3ed87-09b7-4d72-bb21-649f58d44b36"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'distilbert-base-cased'\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "bert_model = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "bert_embeddings = bert_model.get_input_embeddings()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4816c7c96a774acc88d513dde7151fc4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdeabd4bea0c4dd58fad43668814c531",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53ef4727522e4e80b9b7d8f2f4091410",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGFVkcrS1c8i",
        "outputId": "963ff852-b554-4a34-c554-4d6aa84eceac"
      },
      "source": [
        "class TrainDataSet(Dataset):\n",
        "    def __init__(self, excerpts, labels, tokenizer, max_len):\n",
        "        self.excerpts = excerpts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.excerpts)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        excerpt = str(self.excerpts[item])\n",
        "        \n",
        "        encoding  = self.tokenizer.encode_plus(\n",
        "            excerpt,\n",
        "            max_length = self.max_len,\n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'excerpt_text': excerpt,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'targets': torch.tensor(self.labels[item], dtype=torch.long)\n",
        "        }\n",
        "class TestDataSet(Dataset):\n",
        "    def __init__(self, ids, excerpts, tokenizer, max_len):\n",
        "        self.ids = ids\n",
        "        self.excerpts = excerpts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.excerpts)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        excerpt = str(self.excerpts[item])\n",
        "        excerpt_id = str(self.ids[item])\n",
        "        \n",
        "        encoding  = self.tokenizer.encode_plus(\n",
        "            excerpt,\n",
        "            max_length = self.max_len,\n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'excerpt_id': excerpt_id,\n",
        "            'excerpt_text': excerpt,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "        }\n",
        "\n",
        "def create_train_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    excerpts = df['text'].to_numpy(),\n",
        "    print(f'Excerpts size: {len(excerpts)}')\n",
        "    labels = df['author'].to_numpy(),\n",
        "    dataset = TrainDataSet(excerpts=excerpts[0], labels=labels[0], tokenizer=tokenizer, max_len=max_len)\n",
        "    print(f'Dataset size: {len(dataset)}')\n",
        "    return DataLoader(dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
        "\n",
        "def create_test_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    excerpts = df['text'].to_numpy(),\n",
        "    ids = df['index'].to_numpy(),\n",
        "    print(f'Excerpts size: {len(excerpts)}')\n",
        "    dataset = TestDataSet(ids= ids[0], excerpts=excerpts[0], tokenizer=tokenizer, max_len=max_len)\n",
        "    print(f'Dataset size: {len(dataset)}')\n",
        "    return DataLoader(dataset, batch_size=batch_size, num_workers=4)\n",
        "\n",
        "\n",
        "train_set, val_set = train_test_split(train, test_size=0.2)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 160\n",
        "\n",
        "train_data_loader = create_train_data_loader(train_set, tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE)\n",
        "val_data_loader = create_train_data_loader(val_set, tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE)\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Excerpts size: 1\n",
            "Dataset size: 43903\n",
            "Excerpts size: 1\n",
            "Dataset size: 10976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUHJH5vgbwXs"
      },
      "source": [
        "class distilbertclassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(distilbertclassifier, self).__init__()\n",
        "    self.num_labels = train['author'].nunique()\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.distilbert = DistilBertModel.from_pretrained('distilbert-base-cased')\n",
        "    self.classifier = nn.Linear(self.distilbert.config.dim, train['author'].nunique())\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    distilbert_output = self.distilbert(input_ids=input_ids,\n",
        "                                        attention_mask=attention_mask)\n",
        "    hidden_state = distilbert_output[0]\n",
        "    pooled_output = hidden_state[:,0,:]\n",
        "    pooled_output = self.dropout(pooled_output)\n",
        "    logits = self.classifier(pooled_output)\n",
        "    return logits"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOXoArB8i6jp",
        "outputId": "7ba1745d-4ac3-490f-a150-f29a63e1508c"
      },
      "source": [
        "model = distilbertclassifier()\n",
        "model = model.to(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlW0dYQTjNaw",
        "outputId": "023a9ff0-48a8-404d-a43c-a61df0387500"
      },
      "source": [
        "model.distilbert.config"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertConfig {\n",
              "  \"_name_or_path\": \"distilbert-base-cased\",\n",
              "  \"activation\": \"gelu\",\n",
              "  \"attention_dropout\": 0.1,\n",
              "  \"dim\": 768,\n",
              "  \"dropout\": 0.1,\n",
              "  \"hidden_dim\": 3072,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"distilbert\",\n",
              "  \"n_heads\": 12,\n",
              "  \"n_layers\": 6,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"qa_dropout\": 0.1,\n",
              "  \"seq_classif_dropout\": 0.2,\n",
              "  \"sinusoidal_pos_embds\": false,\n",
              "  \"tie_weights_\": true,\n",
              "  \"transformers_version\": \"4.9.0\",\n",
              "  \"vocab_size\": 28996\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIZ2UfuIjTJ_"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HCkEqSPjSIa"
      },
      "source": [
        "epochs = 3\n",
        "if torch.cuda.is_available():\n",
        "  optimizer = transformers.AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "  total_steps = len(train_data_loader) * epochs\n",
        "  scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "  loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QZ9AgbtkAB3"
      },
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, scheduler, n_examples):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_pred = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attention_mask = d['attention_mask'].to(device)\n",
        "    targets = d['targets'].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    correct_pred += torch.sum(preds==targets)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "  return correct_pred.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1mtEBI8lGHi"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_preds = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d['input_ids'].to(device)\n",
        "      attention_mask = d['attention_mask'].to(device)\n",
        "      targets = d['targets'].to(device)\n",
        "\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "      correct_preds += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "  return correct_preds/ n_examples, np.mean(losses)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GysVrn-lxHt"
      },
      "source": [
        "def predict(model, data_loader, submission_df):\n",
        "  model = model.eval()\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d['input_ids'].to(device)\n",
        "      attention_mask = d['attention_mask'].to(device)\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      print(outputs)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HCayV7omDhB",
        "outputId": "5968ea65-aeee-40ae-90be-047b06a03641"
      },
      "source": [
        "filename = 'final.pt'\n",
        "\n",
        "model = model.to(device)\n",
        "history={}\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(f'Epoch {epoch + 1}/{epochs}')\n",
        "  print('-'*10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(model=model, data_loader=train_data_loader,\n",
        "                                      loss_fn=loss_fn,\n",
        "                                      optimizer=optimizer,\n",
        "                                      scheduler=scheduler,\n",
        "                                      n_examples=len(train_set))\n",
        "  print(f'Train loss:{train_loss}, accuracy:{train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(model, val_data_loader,\n",
        "                                 loss_fn,\n",
        "                                 n_examples=len(val_set))\n",
        "  print(f'Validation loss:{val_loss}, accuracy:{val_acc}')\n",
        "\n",
        "torch.save(model.state_dict(), filename)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss:0.22355468708024978, accuracy:0.9245154089697744\n",
            "Validation loss:0.19091577128623952, accuracy:0.9392310976982117\n",
            "Epoch 2/3\n",
            "----------\n",
            "Train loss:0.22652045020478256, accuracy:0.9240143042616679\n",
            "Validation loss:0.1909157702179677, accuracy:0.9392310976982117\n",
            "Epoch 3/3\n",
            "----------\n",
            "Train loss:0.22444245059532927, accuracy:0.9246976288636313\n",
            "Validation loss:0.19091577061320283, accuracy:0.9392310976982117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlvWGt1kCG_W",
        "outputId": "745f064f-1a9e-4dda-b15a-cb3c3a54941f"
      },
      "source": [
        "test_data_loader = create_test_data_loader(test, tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE)\n",
        "\n",
        "sample = next(iter(test_data_loader))\n",
        "\n",
        "input_ids = sample['input_ids'].to(device)\n",
        "attention_mask = sample['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape)\n",
        "print(attention_mask.shape)\n",
        "prob, pred = torch.max(model(input_ids=input_ids, attention_mask=attention_mask),dim=1)\n",
        "print(prob)\n",
        "print(pred)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Excerpts size: 1\n",
            "Dataset size: 19617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "tensor([ 5.0812,  7.6404, 10.3209,  7.4818,  6.9561, 10.4946,  7.0634,  3.1641,\n",
            "        10.9128,  6.6594, 12.2653,  7.9196, 12.5967, 10.6816, 12.0638,  6.2681],\n",
            "       device='cuda:0', grad_fn=<MaxBackward0>)\n",
            "tensor([3, 1, 0, 2, 0, 3, 3, 1, 0, 0, 3, 4, 1, 2, 2, 0], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9r4TFp_92-e"
      },
      "source": [
        "def test_model(model, data_loader, results_df):\n",
        "  model = model.eval()\n",
        "  submission = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      excerpt_ids = d['excerpt_id']\n",
        "      input_ids = d['input_ids'].to(device)\n",
        "      attention_mask = d['attention_mask'].to(device)\n",
        "\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      outputs = nn.functional.softmax(outputs, dim=1)\n",
        "      for i, excerpt_id in enumerate(excerpt_ids):\n",
        "        results_df.loc[results_df['index'] == excerpt_id, ['0','1','2','3','4']] =  outputs[i].tolist()\n",
        "\n",
        "  return results_df"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIMt0JHPQADj"
      },
      "source": [
        "# 마지막 proba 얻기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ybZiACmKsxp"
      },
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/dataset/Dacon/연습/소설 작가 분류 AI 경진대회_data/소설 작가 분류 AI 경진대회_data-sample_submission.csv', encoding='utf-8')"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvxSB42MD6gJ",
        "outputId": "c3a80ad3-3dd0-43a8-f68c-f0baefe0f9d3"
      },
      "source": [
        "results_df = test_model(model, test_data_loader, submit)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVPC-cEaOJtV",
        "outputId": "d4ca6a59-a93c-41e7-d08d-d11b7453b105"
      },
      "source": [
        "output = model(input_ids, attention_mask)\n",
        "nn.functional.softmax(output, dim=1)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1774e-03, 2.9400e-01, 1.9017e-02, 6.8580e-01, 4.2090e-06],\n",
              "        [5.1597e-05, 9.9913e-01, 2.0068e-06, 4.8066e-05, 7.7074e-04],\n",
              "        [9.9999e-01, 1.1113e-06, 1.0914e-07, 2.0152e-06, 2.3305e-06],\n",
              "        [1.7971e-05, 1.0480e-02, 9.8948e-01, 2.0416e-05, 3.8130e-06],\n",
              "        [9.9574e-01, 3.9873e-03, 1.4071e-05, 9.7049e-05, 1.5680e-04],\n",
              "        [1.0702e-06, 2.0752e-06, 1.2159e-05, 9.9996e-01, 1.9981e-05],\n",
              "        [1.7768e-05, 6.2105e-05, 4.3146e-04, 9.9917e-01, 3.2071e-04],\n",
              "        [4.5732e-01, 5.3310e-01, 2.4002e-04, 1.1065e-04, 9.2321e-03],\n",
              "        [9.9999e-01, 5.5559e-06, 6.0840e-06, 1.2717e-07, 2.1647e-07],\n",
              "        [9.9157e-01, 7.0728e-03, 5.2034e-06, 1.3035e-03, 4.3497e-05],\n",
              "        [3.6595e-07, 5.9945e-07, 1.1002e-06, 1.0000e+00, 2.8058e-07],\n",
              "        [1.8181e-04, 5.4512e-06, 2.0667e-05, 4.9757e-06, 9.9979e-01],\n",
              "        [1.7410e-06, 1.0000e+00, 2.2274e-08, 6.9940e-08, 1.0018e-07],\n",
              "        [2.5895e-08, 4.6673e-04, 9.9951e-01, 6.6918e-09, 2.6639e-05],\n",
              "        [8.2277e-09, 3.3202e-04, 9.9967e-01, 9.6107e-09, 4.3995e-07],\n",
              "        [9.9766e-01, 5.1814e-05, 1.6144e-05, 1.5591e-03, 7.1183e-04]],\n",
              "       device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    }
  ]
}