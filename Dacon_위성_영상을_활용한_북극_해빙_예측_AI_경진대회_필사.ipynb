{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dacon_위성 영상을 활용한 북극 해빙 예측 AI 경진대회_필사.ipynb",
      "provenance": [],
      "mount_file_id": "1gM7wkd7Q0A4UkLsh4QfKdva7TKKsU7ar",
      "authorship_tag": "ABX9TyOsSsmXzDabsKo7eFGT1Frn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/O-Kpy/Dacon/blob/main/Dacon_%EC%9C%84%EC%84%B1_%EC%98%81%EC%83%81%EC%9D%84_%ED%99%9C%EC%9A%A9%ED%95%9C_%EB%B6%81%EA%B7%B9_%ED%95%B4%EB%B9%99_%EC%98%88%EC%B8%A1_AI_%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C_%ED%95%84%EC%82%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8v9fd8-AEPe",
        "outputId": "403c5fa9-d075-46e4-a1e3-75dd35cf97df"
      },
      "source": [
        "import os \n",
        "from glob import glob\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from torchvision import transforms, utils\n",
        "from torchsummary import summary \n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using PyTorch version:',  torch.__version__, 'and Device:', device)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 1.8.1+cu101 and Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j2sCY643LZb",
        "outputId": "5ab7272c-a251-4138-94d8-196717acd557"
      },
      "source": [
        "pip install catboost"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/41/24e14322b9986cf72a8763e0a0a69cc256cf963cf9502c8f0044a62c1ae8/catboost-0.26-cp37-none-manylinux1_x86_64.whl (69.2MB)\n",
            "\u001b[K     |████████████████████████████████| 69.2MB 43kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hnFLf_DCi25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "39a89084-3eb9-4e22-f1ed-7b4214aeb0d6"
      },
      "source": [
        "import catboost\n",
        "\n",
        "model=catboost.CatBoostRegressor()\n",
        "model.fit(eval_metrics)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-63b2f12cffd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'eval_metrics' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9INMy4DsRRk"
      },
      "source": [
        "def missing_data(df):\n",
        "    total = df.isnull().sum()\n",
        "    percent = round(df.isnull().sum()/len(df)*100, 2)\n",
        "    \n",
        "    table = pd.concat([total, percent], axis=1, keys=['total', 'percent']).sort_index(by='total', ascending=False)\n",
        "    return table\n",
        "\n",
        "missing_data(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVaVt6BsGngq"
      },
      "source": [
        "# 데이터 불러오기 주소 (os.path.join())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w09o-cEeoUvr"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/dataset/Dacon/연습/제 2회 컴퓨터비전 학습 경진대회/'\n",
        "train_data_path = os.path.join(data_path, 'train')\n",
        "file_list = os.listdir(train_data_path)\n",
        "file_list.sort()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmL5z1EDFvpK",
        "outputId": "268937fb-2f8c-4c7c-b16a-703e43fa6714"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/dataset/Dacon/연습/제 2회 컴퓨터비전 학습 경진대회/'\n",
        "train_data_path = os.path.join(data_path, 'train')\n",
        "print(train_data_path)\n",
        "file_list = os.listdir(train_data_path)\n",
        "file_list.sort()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/dataset/Dacon/연습/제 2회 컴퓨터비전 학습 경진대회/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIysg3FPokZ7"
      },
      "source": [
        "class SealceDataset(Dataset):\n",
        "  def __init__(self, data_dir, transform, data_type='train', frame_num=6, predict_num=2, stride=1):\n",
        "    super(SealceDataset, self).__init__()\n",
        "\n",
        "    data_to_path = os.path.join(data_dir, data_type)\n",
        "    filenames = os.listdir(data_to_path)\n",
        "    self.filepaths = [os.path.join(data_to_path, filename) for filename in sorted(filenames)]\n",
        "\n",
        "    self.transform = transform\n",
        "    self.frame_num = frame_num\n",
        "    self.predict_num = predict_num\n",
        "    self.stride = stride\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filepaths) - (self.frame_num + self.predict_num - 1) * self.stride\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    dataset = []\n",
        "    for id in range(idx, idx + self.frame_num + self.predict_num, self.stride):\n",
        "      cur_npy = np.load(self.filepaths[id])[:,:,0]/250    # 250을 나눠주어 저장하지 않으면 toTensor했을때 오차값이 크게 생겼습니다\n",
        "      cur_tensor = self.transform(cur_npy)                # tensor로 저장\n",
        "      dataset.append(cur_tensor)\n",
        "    x = torch.stack(dataset[:self.frame_num])\n",
        "    x = x.transpose(0,1).to(dtype=torch.float)              # [1, 6, 448, 304] => [channel, frames, height, width]\n",
        "    y = torch.stack(dataset[self.frame_num:])               \n",
        "    y = y.transpose(0,1)                                    # [1, 2, 448, 304] => [channel, frames, height, width]\n",
        "    return x, y\n",
        "\n",
        "def get_transform():\n",
        "  return transforms.Compose([\n",
        "                             transforms.ToTensor()\n",
        "  ])\n",
        "\n",
        "transform = get_transform()\n",
        "\n",
        "ice_dataset = SealceDataset(data_path, transform, 'train', 6, 2, 1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPeVmWQiqnGr",
        "outputId": "ca381eb2-afe4-4427-9949-a810c57d2253"
      },
      "source": [
        "a,b = ice_dataset[1]\n",
        "a.shape, b.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 6, 448, 304]), torch.Size([1, 2, 448, 304]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qaz9R5kCGlvW",
        "outputId": "b2fd0e55-5979-4e5c-c842-0273a13fc6e7"
      },
      "source": [
        "torch.set_printoptions(threshold=10000) # show all tensor without abbreviation\n",
        "\n",
        "class SeaIceDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform, data_type=\"train\", frame_num=6, predict_num=2, stride=1):\n",
        "        super(SeaIceDataset, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        data_dir                => data folder path\n",
        "        transform               => data to tensor\n",
        "        data_type=\"train\"       => choose train / valid / test\n",
        "        frame_num               => frame nums to use on train \n",
        "        predict_num             => frame nums to predict\n",
        "        stride_num              => stride for frames (if stride=2 => 197811.npy, 198001.npy, 198003.npy ... )\n",
        "                                   만약 8월끼리 비교하고 싶다면 stride = 12 를 넣어준다.\n",
        "        \"\"\"\n",
        "\n",
        "        data_to_path = os.path.join(data_dir, data_type)\n",
        "        filenames = os.listdir(data_to_path)\n",
        "        self.filepaths = [os.path.join(data_to_path, filename) for filename in sorted(filenames)]\n",
        "        \n",
        "        self.transform = transform  # numpy 배열을 tensor 배열로 바꿔주는 함수\n",
        "        self.frame_num = frame_num \n",
        "        self.predict_num = predict_num\n",
        "        self.stride = stride\n",
        "\n",
        "    def __len__(self):\n",
        "        # len = dataset으로 시작가능한 인덱스 번호 \n",
        "        return len(self.filepaths) - (self.frame_num + self.predict_num - 1) * self.stride\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        it will return (x_with_frame_num, y_true_with_predict_num)\n",
        "        if frame_num = 6, predict_num = 2\n",
        "        ((6, 1, 448, 304), (2, 1, 448, 304))\n",
        "        \"\"\"\n",
        "        dataset = []\n",
        "        for id in range(idx, idx + self.frame_num + self.predict_num, self.stride):\n",
        "            cur_npy = np.load(self.filepaths[id])[:,:,0]/250    # 250을 나눠주어 저장하지 않으면 toTensor했을때 오차값이 크게 생겼습니다\n",
        "            cur_tensor = self.transform(cur_npy)                # tensor로 저장\n",
        "            dataset.append(cur_tensor)\n",
        "        x = torch.stack(dataset[:self.frame_num])\n",
        "        x = x.transpose(0,1).to(dtype=torch.float)              # [1, 6, 448, 304] => [channel, frames, height, width]\n",
        "        y = torch.stack(dataset[self.frame_num:])               \n",
        "        y = y.transpose(0,1)                                    # [1, 2, 448, 304] => [channel, frames, height, width]\n",
        "        return x, y\n",
        "\n",
        "def getTransform():\n",
        "    return transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "\n",
        "\n",
        "transform = getTransform()\n",
        "\n",
        "ice_dataset = SeaIceDataset(data_path, transform, \"train\", 6, 2, 1)\n",
        "\n",
        "a,b = ice_dataset[1]        # sample to see \n",
        "print(len(ice_dataset))     # 데이터셋에 있는 총 데이터의 개수는 8개씩 묶여있는 475개의 데이터가 있습니다\n",
        "print(a.shape, b.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "475\n",
            "torch.Size([1, 6, 448, 304]) torch.Size([1, 2, 448, 304])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkoPcRqGrrzn",
        "outputId": "7d936956-0580-4295-9337-4b89cb1dd80e"
      },
      "source": [
        "len_ice_dataset=len(ice_dataset)\n",
        "len_ice_train = int(0.8*len_ice_dataset)\n",
        "len_ice_valid = len_ice_dataset - len_ice_train\n",
        "\n",
        "train_dataset, valid_dataset = random_split(ice_dataset, [len_ice_train, len_ice_valid])  # random_split을 한다. ice_dataset을 train개수와 valid개수 만큼\n",
        "\n",
        "for x, y in train_dataset:\n",
        "  print(x.shape, y.shape)\n",
        "  break\n",
        "\n",
        "# 잘 나뉘어졌다"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6, 448, 304]) torch.Size([1, 2, 448, 304])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1k1b6h2GrwV",
        "outputId": "34d696c7-bea5-4723-e02e-5628aa0be0da"
      },
      "source": [
        "# Create splited Dataset to Train and Valid\n",
        "\n",
        "len_ice_dataset = len(ice_dataset)\n",
        "len_ice_train = int(0.8*len_ice_dataset)\n",
        "len_ice_valid = len_ice_dataset - len_ice_train\n",
        "\n",
        "\n",
        "train_dataset, valid_dataset = random_split(ice_dataset, [len_ice_train, len_ice_valid])\n",
        "print(f\"train dataset length : {len(train_dataset)}\")\n",
        "print(f\"valid dataset length : {len(valid_dataset)}\")\n",
        "\n",
        "# show one of train_ds\n",
        "for x, y in train_dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train dataset length : 380\n",
            "valid dataset length : 95\n",
            "torch.Size([1, 6, 448, 304]) torch.Size([1, 2, 448, 304])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR1RteJysVs2",
        "outputId": "3d8d7835-3cac-4444-f11a-5c604e0cf43e"
      },
      "source": [
        "batch_size = 12\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "for x, y in train_dataloader:\n",
        "  print(x.shape, y.shape)\n",
        "  break"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12, 1, 6, 448, 304]) torch.Size([12, 1, 2, 448, 304])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naX9xfmgGr1D",
        "outputId": "5f4792d1-a668-46ea-9d3c-cb29141e7c6f"
      },
      "source": [
        "# Creating DataLoader\n",
        "# too slow now...\n",
        "\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "# Dataloader 클래스는 데이터셋에서 배치 개수만큼 뽑아서 제공해줍니다\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# show example\n",
        "# train_dataloader length => 32\n",
        "for x, y in train_dataloader:\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12, 1, 6, 448, 304]) torch.Size([12, 1, 2, 448, 304])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df7cCS7ZOoVZ"
      },
      "source": [
        "# Building Model 모델 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ7fFFoytcek"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auu769iWOfSi"
      },
      "source": [
        "model_params = {'shape':(6,1,448,304),\n",
        "                'init_filters':8,\n",
        "                'dropout_rate':0.5}\n",
        "\n",
        "# Creating Model\n",
        "\n",
        "class CustomNet(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(CustomNet, self).__init__()\n",
        "        input_frames, input_channel, input_height, input_width = params[\"shape\"]\n",
        "        init_filters = params[\"init_filters\"]\n",
        "        self.dropout_rate = params[\"dropout_rate\"]\n",
        "        self.conv1 = nn.Conv3d(input_channel, init_filters, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv3d(init_filters, init_filters*2, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.ConvTranspose3d(init_filters*2, 1, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = x\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool3d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.upsample(x, size=(2, 448, 304))\n",
        "        print(\"input: \", input.shape)\n",
        "        print(\"output: \", x.shape)\n",
        "        return x\n",
        "\n",
        "  # Linear가 없네?"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAnNrhlbQDID",
        "outputId": "61cb4d4c-b636-432a-ca9d-b13dd6672f4c"
      },
      "source": [
        "my_model = CustomNet(model_params).to(device)\n",
        "print(my_model)\n",
        "summary(my_model, input_size=(1,6,448,304), device=device)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CustomNet(\n",
            "  (conv1): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (conv2): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (conv3): ConvTranspose3d(16, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            ")\n",
            "input:  torch.Size([2, 1, 6, 448, 304])\n",
            "output:  torch.Size([2, 1, 2, 448, 304])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1       [-1, 8, 6, 448, 304]             224\n",
            "            Conv3d-2      [-1, 16, 3, 224, 152]           3,472\n",
            "   ConvTranspose3d-3       [-1, 1, 3, 224, 152]             433\n",
            "================================================================\n",
            "Total params: 4,129\n",
            "Trainable params: 4,129\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.12\n",
            "Forward/backward pass size (MB): 63.12\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 66.26\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPgK8fryV6Gq"
      },
      "source": [
        "# Loss Function && metric Function\n",
        "\n",
        "# metrics\n",
        "def mae_score(true, pred):\n",
        "    true, pred = numpy_to_tensor(true, pred)\n",
        "    score = np.mean(np.abs(true-pred))\n",
        "    \n",
        "    return score\n",
        "\n",
        "# metrics\n",
        "def f1_score(true, pred):\n",
        "    true, pred = numpy_to_tensor(true, pred)\n",
        "\n",
        "    target = np.where((true>1*0.05)<1*0.5)\n",
        "    \n",
        "    true = true[target]\n",
        "    pred = pred[target]\n",
        "    true = np.where(true < 1*0.15, 0, 1)\n",
        "    pred = np.where(pred < 1*0.15, 0, 1)\n",
        "    \n",
        "    right = np.sum(true * pred == 1)\n",
        "    precision = right / np.sum(true+1e-8)\n",
        "    recall = right / np.sum(pred+1e-8)\n",
        "    score = 2 * precision*recall/(precision+recall+1e-8)\n",
        "    \n",
        "    return score\n",
        "    \n",
        "# loss function\n",
        "def mae_over_f1(true, pred):\n",
        "    mae = mae_score(true, pred)\n",
        "    f1 = f1_score(true, pred)\n",
        "    score = mae/(f1+1e-8)\n",
        "    \n",
        "    return score\n",
        "\n",
        "def numpy_to_tensor(true, pred):\n",
        "    return true.cpu().detach().numpy(), pred.cpu().detach().numpy()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI4DSoTUXQ1t",
        "outputId": "366b082a-b7f6-4d98-88d0-6b52cd617378"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "# adam optimizer\n",
        "opt_adam = optim.Adam(my_model.parameters(), lr=3e-4)\n",
        "\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group[\"lr\"]\n",
        "\n",
        "# check our learning rate\n",
        "current_lr = get_lr(opt_adam)\n",
        "print(f\"current_lr = {current_lr}\")\n",
        "\n",
        "\n",
        "\n",
        "# learning rate scheduler\n",
        "lr_scheduler = ReduceLROnPlateau(opt_adam, mode=\"min\", factor=0.5, patience=20, verbose=1)\n",
        "\n",
        "# example \n",
        "for i in range(100):\n",
        "    lr_scheduler.step(i)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current_lr = 0.0003\n",
            "Epoch    22: reducing learning rate of group 0 to 1.5000e-04.\n",
            "Epoch    43: reducing learning rate of group 0 to 7.5000e-05.\n",
            "Epoch    64: reducing learning rate of group 0 to 3.7500e-05.\n",
            "Epoch    85: reducing learning rate of group 0 to 1.8750e-05.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsUsyvFGYJGx"
      },
      "source": [
        "# Training Setting\n",
        "에폭 한번 할때마다 loss_epoch함수\n",
        "\n",
        "dataloader의 x,y 마다 metric_batch를 통해 metric값을 계산\n",
        "\n",
        "loss_batch를 통해 loss값을 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLi1kU4Yxw-V"
      },
      "source": [
        "def metrics_batch(pred, true, metrics):\n",
        "  if metrics:\n",
        "    return list(map(lambda x: x(true, pred), metrics))\n",
        "    mae_score = mae_score(true, pred)\n",
        "    f1_score = f1_score(true, pred)\n",
        "    return (mae_score, f1_score)\n",
        "\n",
        "def loss_batch(loss_func, pred, true, opt=None):\n",
        "  loss = loss_func(true, pred)\n",
        "  with torch.no_grad():\n",
        "    metrics = metrics_batch(pred, true, [mae_score, f1_score])\n",
        "  if opt is not None:\n",
        "    opt.zero_grad()\n",
        "    #loss.backward()\n",
        "    opt.step()\n",
        "  return loss, metrics\n",
        "\n",
        "def loss_epoch(model, loss_func, dataset_dataloader, sanity_check=False, opt=None):\n",
        "  running_loss = 0.0\n",
        "  running_metric = [0.0, 0.0]\n",
        "  len_data = len(dataset_dataloader.dataset)\n",
        "\n",
        "  for x,y in dataset_dataloader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    pred = model(x)\n",
        "    loss, metrics = loss_batch(loss_func, pred, y, opt)\n",
        "    running_loss += loss\n",
        "    if metrics is not None:\n",
        "      for idx, metric_value in enumerate(metrics):\n",
        "        running_metric[idx] += metric_value\n",
        "        \n",
        "        # 문제 있으면 break, 여기서는 True 일때 바로 break\n",
        "    if sanity_check is True:\n",
        "      break\n",
        "    \n",
        "  loss = running_loss / float(len_data)\n",
        "  metrics = list(map(lambda x: x/float(len_data), metrics))\n",
        "  print(loss, metrics)\n",
        "  return loss, metrics"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKDOR6iQYDdz"
      },
      "source": [
        "# Training \n",
        "\n",
        "def metrics_batch(pred, true, metrics):\n",
        "    # if needed add param \"metrics\" to custom\n",
        "    \"\"\"\n",
        "    output will be pred\n",
        "    target will be corrects\n",
        "    \"\"\"\n",
        "    if metrics:\n",
        "        return list(map(lambda x: x(true, pred), metrics))\n",
        "    mae_score = mae_score(true, pred)\n",
        "    f1_score = f1_score(true, pred)\n",
        "    return (mae_score, f1_score)\n",
        "\n",
        "def loss_batch(loss_func, pred, true, opt=None):\n",
        "    \"\"\"\n",
        "    loss_func => mae_over_f1\n",
        "    \"\"\"\n",
        "    loss = loss_func(true, pred)\n",
        "    with torch.no_grad():\n",
        "        metrics = metrics_batch(pred, true, [mae_score, f1_score])\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        # loss.backward()\n",
        "        opt.step()  # 학습이 이뤄지는 곳\n",
        "    return loss, metrics\n",
        "\n",
        "def loss_epoch(model, loss_func, dataset_dataloader, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = [0.0, 0.0]\n",
        "    len_data = len(dataset_dataloader.dataset)\n",
        "\n",
        "    for x, y in dataset_dataloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        # 모델 결과\n",
        "        pred = model(x)\n",
        "        # 손실함수 구하기\n",
        "        loss, metrics = loss_batch(loss_func, pred, y, opt)\n",
        "        # 손실함수 \n",
        "        running_loss += loss\n",
        "        if metrics is not None:\n",
        "            for idx, metric_value in enumerate(metrics):\n",
        "                running_metric[idx] += metric_value\n",
        "        \n",
        "        # 문제 있으면 break, 여기서는 True 일때 바로 break\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "    \n",
        "    loss = running_loss / float(len_data)\n",
        "    metrics = list(map(lambda x: x/float(len_data), metrics))\n",
        "    print(loss, metrics)\n",
        "    return loss, metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BPOsGwHaMpK"
      },
      "source": [
        "loss_func = mae_over_f1\n",
        "opt_adam = optim.Adam(my_model.parameters(), lr=3e-4)\n",
        "lr_scheduler = ReduceLROnPlateau(opt_adam, mode=\"min\", factor=0.5, patience=20, verbose=1)\n",
        "\n",
        "TRAIN_PARAMS = {\n",
        "    \"num_epochs\" : 10,\n",
        "    \"loss_func\" : loss_func,\n",
        "    \"optimizer\" : opt_adam,\n",
        "    \"train_dataloader\" : train_dataloader,\n",
        "    \"valid_dataloader\" : valid_dataloader,\n",
        "    \"sanity_check\" : True,\n",
        "    \"lr_scheduler\" : lr_scheduler,\n",
        "    \"save_path\" : \"./weights.pt\"\n",
        "}"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMX2QMz_ajNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4769c1-fc90-4cb4-b374-d83576a17838"
      },
      "source": [
        "def train(model, params):\n",
        "    num_epochs = params['num_epochs']\n",
        "    loss_func = params['loss_func']\n",
        "    opt = params[\"optimizer\"]\n",
        "    train_dataloader = params['train_dataloader']\n",
        "    valid_dataloader = params['valid_dataloader']\n",
        "    sanity_check = params['sanity_check']\n",
        "    lr_scheduler = params['lr_scheduler']\n",
        "    save_path = params['save_path']\n",
        "\n",
        "    # keep history of the loss and metric\n",
        "    loss_hist = {\n",
        "        \"train\" : [],\n",
        "        \"valid\" : []\n",
        "    }\n",
        "\n",
        "    metrics_hist = {\n",
        "        \"train\" : [],\n",
        "        \"valid\" : []\n",
        "    }\n",
        "\n",
        "    # copy best weights\n",
        "    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "    # init best loss\n",
        "    best_loss = float(\"inf\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(opt)\n",
        "        print(f'Epoch:{epoch}/{num_epochs-1}, current lr:{current_lr}')\n",
        "        model.train()\n",
        "        train_loss, train_metrics = loss_epoch(model, loss_func, train_dataloader, sanity_check, opt)\n",
        "\n",
        "        # save history\n",
        "        loss_hist[\"train\"].append(train_loss)\n",
        "        metrics_hist[\"train\"].append(train_metrics)\n",
        "\n",
        "        # model.eval()\n",
        "        # with torch.no_grad():\n",
        "    \n",
        "\n",
        "    return model, loss_hist, metrics_hist\n",
        "\n",
        "\n",
        "my_model, loss_hist, metrics_hist = train(my_model, TRAIN_PARAMS)\n",
        "\n",
        "print(loss_hist)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0/9, current lr:0.0003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "34149.98191103034 [0.00034149981911030345, 0.0]\n",
            "Epoch:1/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "34149.98191176965 [0.00034149981911769657, 0.0]\n",
            "Epoch:2/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "34149.98191147273 [0.0003414998191147273, 0.0]\n",
            "Epoch:3/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "34149.98191253537 [0.00034149981912535364, 0.0]\n",
            "Epoch:4/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "34149.98191152611 [0.0003414998191152611, 0.0]\n",
            "Epoch:5/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "34149.981909977 [0.00034149981909977004, 0.0]\n",
            "Epoch:6/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "34149.98190707612 [0.00034149981907076124, 0.0]\n",
            "Epoch:7/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "34149.98191076131 [0.0003414998191076131, 0.0]\n",
            "Epoch:8/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "34149.98190902233 [0.00034149981909022337, 0.0]\n",
            "Epoch:9/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "34149.981911222596 [0.00034149981911222595, 0.0]\n",
            "{'train': [34149.98191103034, 34149.98191176965, 34149.98191147273, 34149.98191253537, 34149.98191152611, 34149.981909977, 34149.98190707612, 34149.98191076131, 34149.98190902233, 34149.981911222596], 'valid': []}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}